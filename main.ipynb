{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc744b05-2f93-4c77-8caf-23dd88e89df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai_clip\n",
      "  Downloading openai-clip-1.0.1.tar.gz (1.4 MB)\n",
      "     ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.0/1.4 MB 330.3 kB/s eta 0:00:05\n",
      "     -- ------------------------------------- 0.1/1.4 MB 1.1 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 0.2/1.4 MB 2.0 MB/s eta 0:00:01\n",
      "     ----------- ---------------------------- 0.4/1.4 MB 2.2 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 0.6/1.4 MB 2.5 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 0.7/1.4 MB 2.5 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 0.9/1.4 MB 2.7 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 1.0/1.4 MB 2.8 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 1.2/1.4 MB 2.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.4/1.4 MB 2.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.4/1.4 MB 2.7 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting ftfy (from openai_clip)\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting regex (from openai_clip)\n",
      "  Using cached regex-2024.11.6-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tqdm (from openai_clip)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\grise\\documents\\clip-zero-shot\\clip_env\\lib\\site-packages (from ftfy->openai_clip) (0.2.13)\n",
      "Requirement already satisfied: colorama in c:\\users\\grise\\documents\\clip-zero-shot\\clip_env\\lib\\site-packages (from tqdm->openai_clip) (0.4.6)\n",
      "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.8/44.8 kB 2.2 MB/s eta 0:00:00\n",
      "Using cached regex-2024.11.6-cp311-cp311-win_amd64.whl (274 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Building wheels for collected packages: openai_clip\n",
      "  Building wheel for openai_clip (pyproject.toml): started\n",
      "  Building wheel for openai_clip (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for openai_clip: filename=openai_clip-1.0.1-py3-none-any.whl size=1368637 sha256=dadb19555147c10d60a205ac7ce68812ab56c04d6d8660f426b3e3a8fb6a7809\n",
      "  Stored in directory: c:\\users\\grise\\appdata\\local\\pip\\cache\\wheels\\0d\\17\\90\\042948fd2e2a87f1dcf6db6d438cad015c49db0c53d1d9c7dc\n",
      "Successfully built openai_clip\n",
      "Installing collected packages: tqdm, regex, ftfy, openai_clip\n",
      "Successfully installed ftfy-6.3.1 openai_clip-1.0.1 regex-2024.11.6 tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# we need to install clip as it is not pre-installed\n",
    "# you are also free to use open_clip which provide more models\n",
    "# https://github.com/mlfoundations/open_clip\n",
    "%pip install openai_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaed1566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-1.16.0-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "     ------------------- ------------------ 30.7/60.8 kB 640.0 kB/s eta 0:00:01\n",
      "     -------------------------------- ----- 51.2/60.8 kB 650.2 kB/s eta 0:00:01\n",
      "     -------------------------------------- 60.8/60.8 kB 537.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<2.6,>=1.25.2 in c:\\users\\grise\\documents\\clip-zero-shot\\clip_env\\lib\\site-packages (from scipy) (2.3.1)\n",
      "Downloading scipy-1.16.0-cp311-cp311-win_amd64.whl (38.6 MB)\n",
      "   ---------------------------------------- 0.0/38.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/38.6 MB 5.1 MB/s eta 0:00:08\n",
      "   ---------------------------------------- 0.3/38.6 MB 3.9 MB/s eta 0:00:10\n",
      "   ---------------------------------------- 0.4/38.6 MB 3.6 MB/s eta 0:00:11\n",
      "    --------------------------------------- 0.6/38.6 MB 3.6 MB/s eta 0:00:11\n",
      "    --------------------------------------- 0.7/38.6 MB 3.2 MB/s eta 0:00:12\n",
      "    --------------------------------------- 0.9/38.6 MB 3.2 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 1.0/38.6 MB 3.3 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 1.2/38.6 MB 3.3 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 1.4/38.6 MB 3.2 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 1.5/38.6 MB 3.2 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 1.7/38.6 MB 3.3 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 1.9/38.6 MB 3.2 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 2.0/38.6 MB 3.3 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 2.2/38.6 MB 3.2 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 2.3/38.6 MB 3.2 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 2.5/38.6 MB 3.2 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 2.6/38.6 MB 3.2 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 2.8/38.6 MB 3.2 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 2.9/38.6 MB 3.2 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 3.0/38.6 MB 3.1 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 3.2/38.6 MB 3.1 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 3.2/38.6 MB 3.1 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 3.6/38.6 MB 3.2 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 3.7/38.6 MB 3.2 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 3.9/38.6 MB 3.2 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 4.0/38.6 MB 3.2 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 4.2/38.6 MB 3.2 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 4.3/38.6 MB 3.2 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 4.5/38.6 MB 3.2 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 4.6/38.6 MB 3.2 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 4.8/38.6 MB 3.2 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 4.9/38.6 MB 3.2 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 5.1/38.6 MB 3.2 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 5.3/38.6 MB 3.2 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 5.4/38.6 MB 3.2 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 5.6/38.6 MB 3.2 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 5.7/38.6 MB 3.2 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 5.9/38.6 MB 3.2 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 6.0/38.6 MB 3.2 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 6.2/38.6 MB 3.2 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 6.3/38.6 MB 3.2 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 6.5/38.6 MB 3.2 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 6.7/38.6 MB 3.2 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 6.8/38.6 MB 3.2 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 6.9/38.6 MB 3.2 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 7.1/38.6 MB 3.2 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 7.3/38.6 MB 3.2 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 7.4/38.6 MB 3.2 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 7.6/38.6 MB 3.2 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 7.7/38.6 MB 3.2 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 7.8/38.6 MB 3.2 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 8.0/38.6 MB 3.2 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 8.1/38.6 MB 3.2 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 8.3/38.6 MB 3.2 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 8.5/38.6 MB 3.2 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 8.6/38.6 MB 3.2 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 8.7/38.6 MB 3.2 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 8.9/38.6 MB 3.2 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 9.1/38.6 MB 3.2 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 9.2/38.6 MB 3.2 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 9.4/38.6 MB 3.2 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 9.5/38.6 MB 3.2 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 9.7/38.6 MB 3.2 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 9.8/38.6 MB 3.2 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 10.0/38.6 MB 3.2 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 10.1/38.6 MB 3.2 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 10.3/38.6 MB 3.2 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 10.4/38.6 MB 3.2 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 10.5/38.6 MB 3.2 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 10.7/38.6 MB 3.2 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 10.9/38.6 MB 3.2 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 11.1/38.6 MB 3.2 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 11.2/38.6 MB 3.2 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 11.4/38.6 MB 3.2 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 11.5/38.6 MB 3.2 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 11.7/38.6 MB 3.2 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 11.8/38.6 MB 3.2 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 12.0/38.6 MB 3.2 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 12.1/38.6 MB 3.2 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 12.3/38.6 MB 3.2 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 12.4/38.6 MB 3.2 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 12.6/38.6 MB 3.2 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 12.8/38.6 MB 3.2 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 12.9/38.6 MB 3.2 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 13.0/38.6 MB 3.2 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 13.2/38.6 MB 3.2 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 13.3/38.6 MB 3.2 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 13.5/38.6 MB 3.2 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 13.6/38.6 MB 3.2 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 13.8/38.6 MB 3.2 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 13.9/38.6 MB 3.2 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 14.1/38.6 MB 3.2 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 14.3/38.6 MB 3.2 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 14.4/38.6 MB 3.2 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 14.6/38.6 MB 3.2 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 14.7/38.6 MB 3.2 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 14.9/38.6 MB 3.2 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 15.0/38.6 MB 3.2 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 15.2/38.6 MB 3.2 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 15.4/38.6 MB 3.2 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 15.5/38.6 MB 3.2 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 15.7/38.6 MB 3.2 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 15.8/38.6 MB 3.2 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 16.0/38.6 MB 3.2 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 16.1/38.6 MB 3.2 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 16.3/38.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 16.5/38.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 16.6/38.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 16.8/38.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 16.9/38.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 17.1/38.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 17.3/38.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 17.4/38.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 17.6/38.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 17.7/38.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 17.9/38.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 18.1/38.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 18.2/38.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 18.4/38.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 18.5/38.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 18.7/38.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 18.9/38.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 19.0/38.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 19.1/38.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 19.3/38.6 MB 3.2 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 19.4/38.6 MB 3.2 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 19.6/38.6 MB 3.2 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 19.7/38.6 MB 3.2 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 19.8/38.6 MB 3.2 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 20.0/38.6 MB 3.2 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 20.2/38.6 MB 3.2 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 20.3/38.6 MB 3.2 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 20.5/38.6 MB 3.2 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 20.7/38.6 MB 3.2 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 20.8/38.6 MB 3.2 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 21.0/38.6 MB 3.2 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 21.1/38.6 MB 3.2 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 21.2/38.6 MB 3.2 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 21.4/38.6 MB 3.2 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 21.6/38.6 MB 3.2 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 21.8/38.6 MB 3.2 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 21.9/38.6 MB 3.2 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 22.1/38.6 MB 3.2 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 22.2/38.6 MB 3.2 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 22.4/38.6 MB 3.2 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 22.6/38.6 MB 3.2 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 22.7/38.6 MB 3.2 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 22.9/38.6 MB 3.2 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 23.0/38.6 MB 3.2 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 23.2/38.6 MB 3.2 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 23.3/38.6 MB 3.2 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 23.5/38.6 MB 3.2 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 23.7/38.6 MB 3.2 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 23.8/38.6 MB 3.2 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 24.0/38.6 MB 3.2 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 24.1/38.6 MB 3.2 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 24.2/38.6 MB 3.2 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 24.4/38.6 MB 3.2 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 24.6/38.6 MB 3.2 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 24.7/38.6 MB 3.2 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 24.9/38.6 MB 3.2 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 25.1/38.6 MB 3.2 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 25.3/38.6 MB 3.2 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 25.4/38.6 MB 3.2 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 25.6/38.6 MB 3.2 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 25.7/38.6 MB 3.2 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 25.9/38.6 MB 3.2 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 26.0/38.6 MB 3.2 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 26.2/38.6 MB 3.2 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 26.3/38.6 MB 3.2 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 26.5/38.6 MB 3.2 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 26.6/38.6 MB 3.2 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 26.8/38.6 MB 3.2 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 27.0/38.6 MB 3.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 27.1/38.6 MB 3.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 27.3/38.6 MB 3.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 27.4/38.6 MB 3.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 27.6/38.6 MB 3.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 27.8/38.6 MB 3.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 27.9/38.6 MB 3.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 28.1/38.6 MB 3.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 28.2/38.6 MB 3.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 28.4/38.6 MB 3.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 28.5/38.6 MB 3.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 28.7/38.6 MB 3.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 28.8/38.6 MB 3.2 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 29.0/38.6 MB 3.2 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 29.1/38.6 MB 3.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 29.3/38.6 MB 3.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 29.4/38.6 MB 3.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 29.5/38.6 MB 3.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 29.7/38.6 MB 3.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 29.9/38.6 MB 3.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 30.0/38.6 MB 3.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 30.2/38.6 MB 3.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 30.4/38.6 MB 3.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 30.5/38.6 MB 3.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 30.7/38.6 MB 3.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 30.8/38.6 MB 3.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 30.9/38.6 MB 3.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 31.1/38.6 MB 3.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 31.2/38.6 MB 3.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 31.4/38.6 MB 3.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 31.5/38.6 MB 3.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 31.7/38.6 MB 3.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 31.9/38.6 MB 3.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 32.0/38.6 MB 3.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 32.2/38.6 MB 3.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 32.3/38.6 MB 3.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.5/38.6 MB 3.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.7/38.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 32.8/38.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.0/38.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.2/38.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.3/38.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.5/38.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.6/38.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 33.8/38.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 33.9/38.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 34.1/38.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 34.3/38.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 34.4/38.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 34.6/38.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 34.7/38.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 34.9/38.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 35.1/38.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 35.2/38.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 35.4/38.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 35.5/38.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.7/38.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 35.8/38.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.0/38.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.2/38.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.3/38.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.5/38.6 MB 3.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 36.6/38.6 MB 3.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 36.8/38.6 MB 3.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.0/38.6 MB 3.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.1/38.6 MB 3.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.3/38.6 MB 3.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.4/38.6 MB 3.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.6/38.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  37.7/38.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  37.9/38.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.0/38.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.2/38.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.3/38.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/38.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.6/38.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.6/38.6 MB 3.1 MB/s eta 0:00:00\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# %pip install torch\n",
    "# %pip install torchvision\n",
    "# %pip install tqdm\n",
    "%pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e532365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import clip\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594dc500",
   "metadata": {},
   "source": [
    "## Dataset Loading\n",
    "Let's get the data directly from torchvision as we have seen during labs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17adce24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_dir=\"./data\", transform=None):\n",
    "    \"\"\"Load Flowers102 train, validation and test sets.\n",
    "    Args:\n",
    "        data_dir (str): Directory where the dataset will be stored.\n",
    "        transform (torch.Compose)\n",
    "    Returns:\n",
    "        tuple: A tuple containing the train, validation, and test sets.\n",
    "    \"\"\"\n",
    "    train = torchvision.datasets.Flowers102(root=data_dir, split=\"train\", download=True, transform=transform)\n",
    "    val = torchvision.datasets.Flowers102(root=data_dir, split=\"val\", download=True, transform=transform)\n",
    "    test = torchvision.datasets.Flowers102(root=data_dir, split=\"test\", download=True, transform=transform)\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b846a93f",
   "metadata": {},
   "source": [
    "## Base and Novel categories\n",
    "To split in base and novel categories we list all dataset classes, and count their number (we already know it's 102 but let's do it properly).\n",
    "Then, we just allocate the first half to base categories and the remaining half to novel ones.\n",
    "We can do this because we are simulating a real world application, but keep in mind this will not happen out there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c9c99bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_novel_categories(dataset):\n",
    "    # set returns the unique set of all dataset classes\n",
    "    all_classes = set(dataset._labels)\n",
    "    # and let's count them\n",
    "    num_classes = len(all_classes)\n",
    "\n",
    "    # here list(range(num_classes)) returns a list from 0 to num_classes - 1\n",
    "    # then we slice the list in half and generate base and novel category lists\n",
    "    base_classes = list(range(num_classes))[:num_classes//2]\n",
    "    novel_classes = list(range(num_classes))[num_classes//2:]\n",
    "    return base_classes, novel_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d571e6",
   "metadata": {},
   "source": [
    "## Inspect Classes\n",
    "Let's now visualize which are the base and novel classes.\n",
    "To do so, we first get a dummy test set (without augmentations) as we are just interested in the dataset labels. Then, we split it useing `base_novel_categories`.\n",
    "Finally, we use the hard-coded CLASS_NAMES to print the class in natural language.\n",
    "\n",
    "> Note: the list of class names was only recently added to `torchvision.datasets.Flowers102`. To avoid useless errors that can occour to you, we decided to also provide such a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5caeac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Class Names: [(0, 'pink primrose'), (1, 'hard-leaved pocket orchid'), (2, 'canterbury bells'), (3, 'sweet pea'), (4, 'english marigold'), (5, 'tiger lily'), (6, 'moon orchid'), (7, 'bird of paradise'), (8, 'monkshood'), (9, 'globe thistle'), (10, 'snapdragon'), (11, \"colt's foot\"), (12, 'king protea'), (13, 'spear thistle'), (14, 'yellow iris'), (15, 'globe-flower'), (16, 'purple coneflower'), (17, 'peruvian lily'), (18, 'balloon flower'), (19, 'giant white arum lily'), (20, 'fire lily'), (21, 'pincushion flower'), (22, 'fritillary'), (23, 'red ginger'), (24, 'grape hyacinth'), (25, 'corn poppy'), (26, 'prince of wales feathers'), (27, 'stemless gentian'), (28, 'artichoke'), (29, 'sweet william'), (30, 'carnation'), (31, 'garden phlox'), (32, 'love in the mist'), (33, 'mexican aster'), (34, 'alpine sea holly'), (35, 'ruby-lipped cattleya'), (36, 'cape flower'), (37, 'great masterwort'), (38, 'siam tulip'), (39, 'lenten rose'), (40, 'barbeton daisy'), (41, 'daffodil'), (42, 'sword lily'), (43, 'poinsettia'), (44, 'bolero deep blue'), (45, 'wallflower'), (46, 'marigold'), (47, 'buttercup'), (48, 'oxeye daisy'), (49, 'common dandelion'), (50, 'petunia')]\n",
      "Novel Class Names: [(51, 'wild pansy'), (52, 'primula'), (53, 'sunflower'), (54, 'pelargonium'), (55, 'bishop of llandaff'), (56, 'gaura'), (57, 'geranium'), (58, 'orange dahlia'), (59, 'pink-yellow dahlia?'), (60, 'cautleya spicata'), (61, 'japanese anemone'), (62, 'black-eyed susan'), (63, 'silverbush'), (64, 'californian poppy'), (65, 'osteospermum'), (66, 'spring crocus'), (67, 'bearded iris'), (68, 'windflower'), (69, 'tree poppy'), (70, 'gazania'), (71, 'azalea'), (72, 'water lily'), (73, 'rose'), (74, 'thorn apple'), (75, 'morning glory'), (76, 'passion flower'), (77, 'lotus'), (78, 'toad lily'), (79, 'anthurium'), (80, 'frangipani'), (81, 'clematis'), (82, 'hibiscus'), (83, 'columbine'), (84, 'desert-rose'), (85, 'tree mallow'), (86, 'magnolia'), (87, 'cyclamen'), (88, 'watercress'), (89, 'canna lily'), (90, 'hippeastrum'), (91, 'bee balm'), (92, 'ball moss'), (93, 'foxglove'), (94, 'bougainvillea'), (95, 'camellia'), (96, 'mallow'), (97, 'mexican petunia'), (98, 'bromelia'), (99, 'blanket flower'), (100, 'trumpet creeper'), (101, 'blackberry lily')]\n"
     ]
    }
   ],
   "source": [
    "_, _, tmp_test = get_data()\n",
    "base_classes, novel_classes = base_novel_categories(tmp_test)\n",
    "CLASS_NAMES = [\"pink primrose\", \"hard-leaved pocket orchid\", \"canterbury bells\", \"sweet pea\", \"english marigold\", \"tiger lily\", \"moon orchid\", \"bird of paradise\", \"monkshood\", \"globe thistle\", \"snapdragon\", \"colt's foot\", \"king protea\", \"spear thistle\", \"yellow iris\", \"globe-flower\", \"purple coneflower\", \"peruvian lily\", \"balloon flower\", \"giant white arum lily\", \"fire lily\", \"pincushion flower\", \"fritillary\", \"red ginger\", \"grape hyacinth\", \"corn poppy\", \"prince of wales feathers\", \"stemless gentian\", \"artichoke\", \"sweet william\", \"carnation\", \"garden phlox\", \"love in the mist\", \"mexican aster\", \"alpine sea holly\", \"ruby-lipped cattleya\", \"cape flower\", \"great masterwort\", \"siam tulip\", \"lenten rose\", \"barbeton daisy\", \"daffodil\", \"sword lily\", \"poinsettia\", \"bolero deep blue\", \"wallflower\", \"marigold\", \"buttercup\", \"oxeye daisy\", \"common dandelion\", \"petunia\", \"wild pansy\", \"primula\", \"sunflower\", \"pelargonium\", \"bishop of llandaff\", \"gaura\", \"geranium\", \"orange dahlia\", \"pink-yellow dahlia?\", \"cautleya spicata\", \"japanese anemone\", \"black-eyed susan\", \"silverbush\", \"californian poppy\", \"osteospermum\", \"spring crocus\", \"bearded iris\", \"windflower\", \"tree poppy\", \"gazania\", \"azalea\", \"water lily\", \"rose\", \"thorn apple\", \"morning glory\", \"passion flower\", \"lotus\", \"toad lily\", \"anthurium\", \"frangipani\", \"clematis\", \"hibiscus\", \"columbine\", \"desert-rose\", \"tree mallow\", \"magnolia\", \"cyclamen\", \"watercress\", \"canna lily\", \"hippeastrum\", \"bee balm\", \"ball moss\", \"foxglove\", \"bougainvillea\", \"camellia\", \"mallow\", \"mexican petunia\", \"bromelia\", \"blanket flower\", \"trumpet creeper\", \"blackberry lily\"]\n",
    "print(\"Base Class Names:\", [(i, CLASS_NAMES[i]) for i in base_classes])\n",
    "print(\"Novel Class Names:\", [(i, CLASS_NAMES[i]) for i in novel_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7bff10",
   "metadata": {},
   "source": [
    "## Split Dataset\n",
    "The next step is to actually split the dataset into the base and novel categories we extract from `base_novel_categories`.\n",
    "To split the data we need the dataset (obviously) and the list of base classes. If the sample label is not part of the base categories, then it must be part of the novel ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1aa5673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(dataset, base_classes):\n",
    "    # these two lists will store the sample indexes\n",
    "    base_categories_samples = []\n",
    "    novel_categories_samples = []\n",
    "\n",
    "    # we create a set of base classes to compute the test below in O(1)\n",
    "    # this is optional and can be removed\n",
    "    base_set = set(base_classes)\n",
    "\n",
    "    # here we iterate over sample labels and also get the correspondent sample index\n",
    "    for sample_id, label in enumerate(dataset._labels):\n",
    "        if label in base_set:\n",
    "            base_categories_samples.append(sample_id)\n",
    "        else:\n",
    "            novel_categories_samples.append(sample_id)\n",
    "\n",
    "    # here we create the dataset subsets\n",
    "    # the torch Subset is just a wrapper around the dataset\n",
    "    # it simply stores the subset indexes and the original dataset (your_subset.dataset)\n",
    "    # when asking for sample i in the subset, torch will look for its original position in the dataset and retrieve it\n",
    "    # https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset\n",
    "    base_dataset = torch.utils.data.Subset(dataset, base_categories_samples)\n",
    "    novel_dataset = torch.utils.data.Subset(dataset, novel_categories_samples)\n",
    "    return base_dataset, novel_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242ce676",
   "metadata": {},
   "source": [
    "## Load CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22a9babd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 335M/335M [01:50<00:00, 3.17MiB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=224, interpolation=bicubic, max_size=None, antialias=True)\n",
       "    CenterCrop(size=(224, 224))\n",
       "    <function _convert_image_to_rgb at 0x000001FE500D42C0>\n",
       "    ToTensor()\n",
       "    Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# available models = ['RN50', 'RN101', 'RN50x4', 'RN50x16', 'RN50x64', 'ViT-B/32', 'ViT-B/16', 'ViT-L/14', 'ViT-L/14@336px']\n",
    "model, preprocess = clip.load(\"ViT-B/16\", device=device)\n",
    "\n",
    "# preprocess contains CLIP's pre-defined augmentations, let's inspect them!\n",
    "preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ba4855",
   "metadata": {},
   "source": [
    "## Load and Prepare Data\n",
    "Here we get the three dataset split and pass clip pre-defined augmentations.\n",
    "Then, we compute base and novel categories (in this case is redundand as we already did it before).\n",
    "Finally, se split the three datasets into base and novel categories.\n",
    "As we want to use the novel categories only for the test set, we drop `train_novel` and `val_novel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e884ca7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the three datasets\n",
    "train_set, val_set, test_set = get_data(transform=preprocess)\n",
    "\n",
    "# split classes into base and novel\n",
    "base_classes, novel_classes = base_novel_categories(train_set)\n",
    "\n",
    "# split the three datasets\n",
    "train_base, _ = split_data(train_set, base_classes)\n",
    "val_base, _ = split_data(val_set, base_classes)\n",
    "test_base, test_novel = split_data(test_set, base_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a08f04",
   "metadata": {},
   "source": [
    "## Compute Zero-Shot Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d45296",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Zero-shot evaluation on Base Classes:  15%|█▌        | 3/20 [01:00<05:16, 18.60s/it]"
     ]
    }
   ],
   "source": [
    "@torch.no_grad() # we don't want gradients\n",
    "def eval(model, dataset, categories, batch_size, device, label=\"\"):\n",
    "    # let's set the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Remap labels into a contiguous set starting from zero\n",
    "    contig_cat2idx = {cat: idx for idx, cat in enumerate(categories)}\n",
    "\n",
    "    # here we apply the standard CLIP template used for oxford flowers to all categories\n",
    "    # and immediately tokenize each sentence (convert natural language into numbers - feel free to print the text input to inspect them)\n",
    "    text_inputs = clip.tokenize(\n",
    "        [f\"a photo of a {CLASS_NAMES[c]}, a type of flower.\" for c in categories]\n",
    "    ).to(device)\n",
    "\n",
    "    # we can encode the text features once as they are shared for all images\n",
    "    # therefore we do it outside the evaluation loop\n",
    "    text_features = model.encode_text(text_inputs)\n",
    "    # and here we normalize them (standard pratice with CLIP)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    # simple dataloader creation\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    # here we store the number of correct predictions we will make\n",
    "    correct_predictions = 0\n",
    "    for image, target in tqdm(dataloader, desc=label):\n",
    "        # base categories range from 0 to 50, whil novel ones from 51 to 101\n",
    "        # therefore we must map categories to the [0, 50], otherwise we will have wrong predictions\n",
    "        # Map targets in contiguous set starting from zero\n",
    "        # Labels needs to be .long() in pytorch\n",
    "        target = torch.Tensor([contig_cat2idx[t.item()] for t in target]).long()\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # forward image through CLIP image encoder\n",
    "        image_features = model.encode_image(image)\n",
    "        # and normalize\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        # here cosine similarity between image and text features and keep the argmax for every row (every image)\n",
    "        predicted_class = (image_features @ text_features.T).argmax(dim=-1)\n",
    "        # now we check which are correct, and sum them (False == 0, True == 1)\n",
    "        correct_predictions += (predicted_class == target).sum().item()\n",
    "\n",
    "    # and now we compute the accuracy\n",
    "    accuracy = correct_predictions / len(dataset)\n",
    "    return accuracy\n",
    "\n",
    "base_accuracy = eval(model=model, dataset=test_base, categories=base_classes, batch_size=128, device=device, label=\"🧠 Zero-shot evaluation on Base Classes\")\n",
    "novel_accuracy = eval(model=model, dataset=test_novel, categories=novel_classes, batch_size=128, device=device, label=\"🧠 Zero-shot evaluation on Novel Classes\")\n",
    "\n",
    "print()\n",
    "print(f\"🔍 Base classes accuracy: {base_accuracy*100:.2f}%\")\n",
    "print(f\"🔍 Novel classes accuracy: {novel_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378a679a",
   "metadata": {},
   "source": [
    "## Harmonic Mean\n",
    "Few-Shot Adaptations papers usually report the Harmonic Mean.\n",
    "The harmonic mean tends to mitigate the impact of large outliers (base accuracy) and aggravate the impact of small ones (novel accuracy).\n",
    "Thus, achieving very high base accuracies at the expense of the novel accuracy will be penalized by the HM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53ec744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonic_mean(base_accuracy, novel_accuracy):\n",
    "    numerator = 2\n",
    "    denominator = 1 / base_accuracy + 1 / novel_accuracy\n",
    "    hm = numerator / denominator\n",
    "    return hm\n",
    "\n",
    "print(f\"🔍 Harmonic Mean: {harmonic_mean(base_accuracy, novel_accuracy)*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
