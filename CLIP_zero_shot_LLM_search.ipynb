{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYQiprE0pcVD"
      },
      "source": [
        "# CLIP zero-shot Evaluation\n",
        "This short notebook implements the dataset split into base and novel categories (see project assignment) and runs the zero-shot evaluation with CLIP.\n",
        "Feel free to copy the code contained in this notebook or to directly use this notebook as starting point for you project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UzXtFjhh7iOS",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d20125f-98f5-416e-f847-cb7ade8b22d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai_clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "#@title Dependencies Installation\n",
        "%pip install -q openai_clip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QtqdSOr8qqOn",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db485a5f-adc5-4f9f-88f3-acc7b6cdbeee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… All dependencies imported successfully!\n",
            "ðŸ”¥ PyTorch version: 2.6.0+cu124\n",
            "ðŸ–¼ï¸ Torchvision version: 0.21.0+cu124\n",
            "ðŸ¤– CUDA available: True\n",
            "ðŸŽ® GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "#@title Imports\n",
        "import torch\n",
        "import torchvision\n",
        "import clip\n",
        "import os\n",
        "import gc\n",
        "from torchvision import transforms\n",
        "from google.colab import userdata\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Dict, Any\n",
        "import json\n",
        "from torchvision.datasets import Flowers102 as dataset_used\n",
        "import contextlib\n",
        "import numpy as np\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "print(\"âœ… All dependencies imported successfully!\")\n",
        "print(f\"ðŸ”¥ PyTorch version: {torch.__version__}\")\n",
        "print(f\"ðŸ–¼ï¸ Torchvision version: {torchvision.__version__}\")\n",
        "print(f\"ðŸ¤– CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"ðŸŽ® GPU: {torch.cuda.get_device_name()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Classes setup\n",
        "CLASS_NAMES = [\"pink primrose\", \"hard-leaved pocket orchid\", \"canterbury bells\", \"sweet pea\", \"english marigold\", \"tiger lily\", \"moon orchid\", \"bird of paradise\", \"monkshood\", \"globe thistle\", \"snapdragon\", \"colt's foot\", \"king protea\", \"spear thistle\", \"yellow iris\", \"globe-flower\", \"purple coneflower\", \"peruvian lily\", \"balloon flower\", \"giant white arum lily\", \"fire lily\", \"pincushion flower\", \"fritillary\", \"red ginger\", \"grape hyacinth\", \"corn poppy\", \"prince of wales feathers\", \"stemless gentian\", \"artichoke\", \"sweet william\", \"carnation\", \"garden phlox\", \"love in the mist\", \"mexican aster\", \"alpine sea holly\", \"ruby-lipped cattleya\", \"cape flower\", \"great masterwort\", \"siam tulip\", \"lenten rose\", \"barbeton daisy\", \"daffodil\", \"sword lily\", \"poinsettia\", \"bolero deep blue\", \"wallflower\", \"marigold\", \"buttercup\", \"oxeye daisy\", \"common dandelion\", \"petunia\", \"wild pansy\", \"primula\", \"sunflower\", \"pelargonium\", \"bishop of llandaff\", \"gaura\", \"geranium\", \"orange dahlia\", \"pink-yellow dahlia?\", \"cautleya spicata\", \"japanese anemone\", \"black-eyed susan\", \"silverbush\", \"californian poppy\", \"osteospermum\", \"spring crocus\", \"bearded iris\", \"windflower\", \"tree poppy\", \"gazania\", \"azalea\", \"water lily\", \"rose\", \"thorn apple\", \"morning glory\", \"passion flower\", \"lotus\", \"toad lily\", \"anthurium\", \"frangipani\", \"clematis\", \"hibiscus\", \"columbine\", \"desert-rose\", \"tree mallow\", \"magnolia\", \"cyclamen\", \"watercress\", \"canna lily\", \"hippeastrum\", \"bee balm\", \"ball moss\", \"foxglove\", \"bougainvillea\", \"camellia\", \"mallow\", \"mexican petunia\", \"bromelia\", \"blanket flower\", \"trumpet creeper\", \"blackberry lily\"]\n",
        "dataset_name = \"Oxford flowers102\"\n",
        "generic_category = \"flowers\"\n",
        "\n",
        "print(f\"ðŸ“Š Total flower classes: {len(CLASS_NAMES)}\")\n",
        "print(f\"ðŸŒ¸ Sample classes: {CLASS_NAMES[:5]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feUqkSTsvj3b",
        "outputId": "9eb20451-66ba-4648-cc4f-f620214d08ac",
        "cellView": "form"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Total flower classes: 102\n",
            "ðŸŒ¸ Sample classes: ['pink primrose', 'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea', 'english marigold']...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Memory management utils\n",
        "def aggressive_cleanup():\n",
        "    \"\"\"\n",
        "    Comprehensive memory cleanup function to prevent VRAM leaks.\n",
        "\n",
        "    This function:\n",
        "    - Forces Python garbage collection\n",
        "    - Empties CUDA cache\n",
        "    - Collects IPC (Inter-Process Communication) resources\n",
        "    - Synchronizes CUDA operations\n",
        "    \"\"\"\n",
        "    gc.collect()                    # Python garbage collection\n",
        "    torch.cuda.empty_cache()        # Clear CUDA cache\n",
        "    torch.cuda.ipc_collect()        # Clean up IPC resources\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.synchronize()    # Wait for all CUDA operations to complete\n",
        "\n",
        "def print_memory_stats():\n",
        "    \"\"\"Display current GPU memory usage statistics\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        allocated = torch.cuda.memory_allocated() / 1024**3  # Convert to GB\n",
        "        reserved = torch.cuda.memory_reserved() / 1024**3    # Convert to GB\n",
        "        print(f\"ðŸ”‹ GPU Memory: {allocated:.2f}GB allocated, {reserved:.2f}GB reserved\")\n",
        "    else:\n",
        "        print(\"âŒ CUDA not available - running on CPU\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HvcFJ1LL7xO3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "M_1CrUhZpVCq",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Utils functions\n",
        "\n",
        "def get_data(data_dir=\"./data\", transform=None):\n",
        "    \"\"\"Load Flowers102 train, validation and test sets.\n",
        "    Args:\n",
        "        data_dir (str): Directory where the dataset will be stored.\n",
        "        transform (torch.Compose)\n",
        "    Returns:\n",
        "        tuple: A tuple containing the train, validation, and test sets.\n",
        "    \"\"\"\n",
        "    print(\"ðŸ“¥ Downloading and loading Flowers102 dataset...\")\n",
        "    train = dataset_used(root=data_dir, split=\"train\", download=True, transform=transform)\n",
        "    val = dataset_used(root=data_dir, split=\"val\", download=True, transform=transform)\n",
        "    test = dataset_used(root=data_dir, split=\"test\", download=True, transform=transform)\n",
        "    print(f\"âœ… Dataset loaded - Train: {len(train)}, Val: {len(val)}, Test: {len(test)}\")\n",
        "    return train, val, test\n",
        "\n",
        "def base_novel_categories(dataset):\n",
        "    \"\"\"\n",
        "    Split all classes into base and novel categories.\n",
        "\n",
        "    Base classes: First half of classes (for training/fine-tuning scenarios)\n",
        "    Novel classes: Second half of classes (for zero-shot evaluation)\n",
        "\n",
        "    Args:\n",
        "        dataset: PyTorch dataset object\n",
        "\n",
        "    Returns:\n",
        "        base_classes, novel_classes: Lists of class indices\n",
        "    \"\"\"\n",
        "    all_classes = set(dataset._labels)\n",
        "    num_classes = len(all_classes)\n",
        "\n",
        "    # Split classes 50/50\n",
        "    base_classes = list(range(num_classes))[:num_classes//2]\n",
        "    novel_classes = list(range(num_classes))[num_classes//2:]\n",
        "\n",
        "    print(f\"ðŸ“Š Class split - Base: {len(base_classes)}, Novel: {len(novel_classes)}\")\n",
        "    return base_classes, novel_classes\n",
        "\n",
        "def split_data(dataset, base_classes):\n",
        "    \"\"\"\n",
        "    Split dataset samples based on base/novel class membership.\n",
        "\n",
        "    Args:\n",
        "        dataset: PyTorch dataset\n",
        "        base_classes: List of base class indices\n",
        "\n",
        "    Returns:\n",
        "        base_dataset, novel_dataset: Subsets containing only base/novel samples\n",
        "    \"\"\"\n",
        "    base_categories_samples = []\n",
        "    novel_categories_samples = []\n",
        "    base_set = set(base_classes)\n",
        "\n",
        "    # Iterate through all samples and categorize by class\n",
        "    for sample_id, label in enumerate(dataset._labels):\n",
        "        if label in base_set:\n",
        "            base_categories_samples.append(sample_id)\n",
        "        else:\n",
        "            novel_categories_samples.append(sample_id)\n",
        "\n",
        "    # Create dataset subsets\n",
        "    base_dataset = torch.utils.data.Subset(dataset, base_categories_samples)\n",
        "    novel_dataset = torch.utils.data.Subset(dataset, novel_categories_samples)\n",
        "\n",
        "    print(f\"ðŸ“Š Data split - Base samples: {len(base_dataset)}, Novel samples: {len(novel_dataset)}\")\n",
        "    return base_dataset, novel_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title CLIP context manager\n",
        "@contextlib.contextmanager\n",
        "def clip_model_context(model_name=\"ViT-B/16\"):\n",
        "    \"\"\"\n",
        "    Context manager for CLIP model to ensure proper cleanup.\n",
        "\n",
        "    This ensures that:\n",
        "    - Model is properly loaded on the correct device\n",
        "    - Model is set to evaluation mode\n",
        "    - Memory is cleaned up after use, even if errors occur\n",
        "\n",
        "    Args:\n",
        "        model_name: CLIP model variant to load\n",
        "\n",
        "    Yields:\n",
        "        model: CLIP model\n",
        "        preprocess: Image preprocessing function\n",
        "        device: Device (cuda/cpu) the model is loaded on\n",
        "    \"\"\"\n",
        "    print(f\"ðŸ¤– Loading CLIP model: {model_name}\")\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Load CLIP model and preprocessing\n",
        "    model, preprocess = clip.load(model_name, device=device)\n",
        "    model.eval()  # Set to evaluation mode\n",
        "\n",
        "    print(f\"âœ… CLIP model loaded on {device}\")\n",
        "\n",
        "    try:\n",
        "        yield model, preprocess, device\n",
        "    finally:\n",
        "        # Ensure cleanup happens even if errors occur\n",
        "        print(\"ðŸ§¹ Cleaning up CLIP model...\")\n",
        "        del model\n",
        "        aggressive_cleanup()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QDBGk6Z68gbQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Evaluation function\n",
        "@torch.no_grad()\n",
        "def eval(model, dataset, categories, batch_size, device, text_features, label=\"\"):\n",
        "    \"\"\"\n",
        "    Memory-optimized evaluation function for CLIP zero-shot classification.\n",
        "\n",
        "    Computes:\n",
        "    - Top-1, Top-5, Top-10 accuracies\n",
        "    - Confidence gaps between predicted and true classes\n",
        "    - Splits confidence gaps by error type (top-1 hit, top-5 hit, etc.)\n",
        "\n",
        "    Args:\n",
        "        model: CLIP model\n",
        "        dataset: PyTorch dataset to evaluate\n",
        "        categories: List of class indices for this evaluation\n",
        "        batch_size: Batch size for evaluation\n",
        "        device: Device to run on\n",
        "        text_features: Pre-computed text embeddings\n",
        "        label: Description label for progress bar\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with accuracy metrics and confidence gaps\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Create mapping from original class IDs to contiguous indices (0, 1, 2, ...)\n",
        "    contig_cat2idx = {cat: idx for idx, cat in enumerate(categories)}\n",
        "\n",
        "    # Create dataloader (num_workers=0 to avoid subprocess memory issues in Colab)\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=False, num_workers=0\n",
        "    )\n",
        "\n",
        "    # Initialize counters\n",
        "    correct_top1 = 0\n",
        "    correct_top5 = 0\n",
        "    correct_top10 = 0\n",
        "    total = 0\n",
        "\n",
        "    # Lists to store confidence gaps for different error categories\n",
        "    gap_top1_hit = []      # When prediction is correct\n",
        "    gap_top5_hit = []      # When true class is in top-5 but not top-1\n",
        "    gap_top10_hit = []     # When true class is in top-10 but not top-5\n",
        "    gap_top10_miss = []    # When true class is not in top-10\n",
        "\n",
        "    try:\n",
        "        for batch_idx, (images, targets) in enumerate(tqdm(dataloader, desc=label)):\n",
        "            # Remap targets to contiguous space and move to device\n",
        "            targets = torch.tensor([contig_cat2idx[t.item()] for t in targets], dtype=torch.long).to(device)\n",
        "            images = images.to(device)\n",
        "\n",
        "            # Encode images\n",
        "            image_features = model.encode_image(images)\n",
        "            image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            # Compute similarities between images and text\n",
        "            similarities = image_features @ text_features.T\n",
        "\n",
        "            # Get top-10 predictions\n",
        "            top10 = similarities.topk(10, dim=-1)\n",
        "            top10_indices = top10.indices  # Class predictions\n",
        "            top10_values = top10.values    # Confidence scores\n",
        "\n",
        "            # Calculate accuracies\n",
        "            correct_top1 += (top10_indices[:, 0] == targets).sum().item()\n",
        "            correct_top5 += sum([targets[i] in top10_indices[i, :5] for i in range(len(targets))])\n",
        "            correct_top10 += sum([targets[i] in top10_indices[i, :10] for i in range(len(targets))])\n",
        "\n",
        "            # Calculate confidence gaps for each sample\n",
        "            for i in range(len(targets)):\n",
        "                true_idx = targets[i].item()\n",
        "                pred_conf = top10_values[i, 0].item()  # Highest prediction confidence\n",
        "                true_conf = similarities[i, true_idx].item()  # True class confidence\n",
        "\n",
        "                # Categorize by error type\n",
        "                if top10_indices[i, 0].item() == true_idx:\n",
        "                    # Correct prediction - gap between 1st and 2nd choice\n",
        "                    second_conf = top10_values[i, 1].item()\n",
        "                    gap_top1_hit.append((pred_conf - second_conf) * 100)\n",
        "                elif true_idx in top10_indices[i, 1:5]:\n",
        "                    # True class in top-5 but not top-1\n",
        "                    gap_top5_hit.append((pred_conf - true_conf) * 100)\n",
        "                elif true_idx in top10_indices[i, 5:10]:\n",
        "                    # True class in top-10 but not top-5\n",
        "                    gap_top10_hit.append((pred_conf - true_conf) * 100)\n",
        "                else:\n",
        "                    # True class not in top-10\n",
        "                    gap_top10_miss.append((pred_conf - true_conf) * 100)\n",
        "\n",
        "            total += targets.size(0)\n",
        "\n",
        "            # Clean up batch tensors immediately to save memory\n",
        "            del images, targets, image_features, similarities, top10, top10_indices, top10_values\n",
        "\n",
        "            # Periodic cleanup during long evaluations\n",
        "            if batch_idx % 10 == 0:\n",
        "                aggressive_cleanup()\n",
        "\n",
        "    finally:\n",
        "        # Clean up dataloader\n",
        "        del dataloader\n",
        "        aggressive_cleanup()\n",
        "\n",
        "    # Calculate final metrics\n",
        "    top1_acc = correct_top1 / total\n",
        "    top5_acc = correct_top5 / total\n",
        "    top10_acc = correct_top10 / total\n",
        "\n",
        "    # Display results\n",
        "    print(f\"\\nðŸ“Š Total samples evaluated: {total}\\n\")\n",
        "    print(f\"âœ… Top-1 Accuracy:      {top1_acc*100:.2f}%\")\n",
        "    print(f\"âœ… Top-5 Accuracy:      {top5_acc*100:.2f}%\")\n",
        "    print(f\"âœ… Top-10 Accuracy:     {top10_acc*100:.2f}%\")\n",
        "    print(f\"âœ… Avg. Conf. Gap (Top-1 hit):      {safe_mean(gap_top1_hit):.2f}%\")\n",
        "    print(f\"âŒ Avg. Conf. Gap (Top-5 hit):     {safe_mean(gap_top5_hit):.2f}%\")\n",
        "    print(f\"âŒ Avg. Conf. Gap (Top-10 hit):    {safe_mean(gap_top10_hit):.2f}%\")\n",
        "    print(f\"âŒ Avg. Conf. Gap (Beyond top-10): {safe_mean(gap_top10_miss):.2f}%\")\n",
        "\n",
        "    return {\n",
        "        \"top1\": top1_acc,\n",
        "        \"top5\": top5_acc,\n",
        "        \"top10\": top10_acc,\n",
        "        \"avg_gap_top1_hit\": safe_mean(gap_top1_hit),\n",
        "        \"avg_error_top5_hit\": safe_mean(gap_top5_hit),\n",
        "        \"avg_error_top10_hit\": safe_mean(gap_top10_hit),\n",
        "        \"avg_error_top10_miss\": safe_mean(gap_top10_miss),\n",
        "    }"
      ],
      "metadata": {
        "cellView": "form",
        "id": "mrRHjqc68W2v"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Text features functions\n",
        "def get_text_features_standard(model, class_ids, device):\n",
        "    \"\"\"\n",
        "    Generate standard CLIP text features using simple template prompts.\n",
        "\n",
        "    Uses the template: \"a photo of a {class_name}, a type of flower.\"\n",
        "\n",
        "    Args:\n",
        "        model: CLIP model\n",
        "        class_ids: List of class indices to generate features for\n",
        "        device: Device to run computation on\n",
        "\n",
        "    Returns:\n",
        "        text_features: Normalized text embeddings tensor\n",
        "    \"\"\"\n",
        "    # Create simple template prompts\n",
        "    prompts = [f\"a photo of a {CLASS_NAMES[c]}, a type of flower.\" for c in class_ids]\n",
        "    print(f\"ðŸ“ Generated {len(prompts)} standard prompts\")\n",
        "    print(f\"ðŸ“„ Example prompt: '{prompts[0]}'\")\n",
        "\n",
        "    # Tokenize prompts\n",
        "    text_inputs = clip.tokenize(prompts).to(device)\n",
        "\n",
        "    try:\n",
        "        # Generate embeddings\n",
        "        with torch.no_grad():\n",
        "            text_features = model.encode_text(text_inputs)\n",
        "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        # Create a copy to ensure we don't keep references\n",
        "        result = text_features.clone()\n",
        "        return result\n",
        "\n",
        "    finally:\n",
        "        # Clean up intermediate tensors\n",
        "        del text_inputs, text_features\n",
        "        aggressive_cleanup()\n",
        "\n",
        "def get_llm_text_features(model, prompt_dict, class_ids, class_names, device):\n",
        "    \"\"\"\n",
        "    Generate text features from LLM-generated prompts.\n",
        "\n",
        "    For each class, uses multiple detailed prompts generated by an LLM,\n",
        "    then averages their embeddings to get a richer representation.\n",
        "\n",
        "    Args:\n",
        "        model: CLIP model\n",
        "        prompt_dict: Dictionary mapping class names to lists of prompts\n",
        "        class_ids: List of class indices\n",
        "        class_names: List of all class names\n",
        "        device: Device to run computation on\n",
        "\n",
        "    Returns:\n",
        "        text_features: Tensor of averaged normalized embeddings per class\n",
        "    \"\"\"\n",
        "    text_features = []\n",
        "\n",
        "    print(f\"ðŸ¤– Processing LLM-generated prompts for {len(class_ids)} classes...\")\n",
        "\n",
        "    for c in class_ids:\n",
        "        class_name = class_names[c]\n",
        "        prompts = prompt_dict[class_name]\n",
        "\n",
        "        #print(f\"ðŸ“ Processing {len(prompts)} prompts for '{class_name}'\")\n",
        "\n",
        "        # Tokenize all prompts for this class\n",
        "        text_inputs = clip.tokenize(prompts).to(device)\n",
        "\n",
        "        try:\n",
        "            # Generate embeddings for all prompts\n",
        "            with torch.no_grad():\n",
        "                embeddings = model.encode_text(text_inputs)\n",
        "                embeddings = embeddings / embeddings.norm(dim=-1, keepdim=True)\n",
        "\n",
        "                # Average across all prompts for this class\n",
        "                mean_embedding = embeddings.mean(dim=0)\n",
        "                mean_embedding = mean_embedding / mean_embedding.norm(dim=-1, keepdim=True)\n",
        "\n",
        "                # Store the averaged embedding\n",
        "                text_features.append(mean_embedding.clone())\n",
        "\n",
        "        finally:\n",
        "            # Clean up intermediate tensors\n",
        "            del text_inputs, embeddings, mean_embedding\n",
        "            aggressive_cleanup()\n",
        "\n",
        "    return torch.stack(text_features).to(device)\n",
        "\n",
        "def safe_mean(arr):\n",
        "    \"\"\"Safely compute mean, returning 0 if array is empty\"\"\"\n",
        "    return np.mean(arr) if arr else 0.0"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vCVSIRgR8zzT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Evaluation suite\n",
        "def run_evaluation_suite():\n",
        "    \"\"\"\n",
        "    Run complete evaluation suite with proper memory management.\n",
        "\n",
        "    Evaluations performed:\n",
        "    1. Standard prompts on base classes\n",
        "    2. Standard prompts on novel classes\n",
        "    3. LLM-enhanced prompts on base classes (if available)\n",
        "    4. LLM-enhanced prompts on novel classes (if available)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing all evaluation results\n",
        "    \"\"\"\n",
        "    print(\"ðŸš€ Starting memory-optimized CLIP evaluation suite...\")\n",
        "\n",
        "    # Try to load LLM-generated prompts\n",
        "    try:\n",
        "        with open(\"generated_prompts.json\", \"r\") as f:\n",
        "            generated_prompts_for_classes = json.load(f)\n",
        "        has_llm_prompts = True\n",
        "        print(\"âœ… Found generated prompts file\")\n",
        "        print(f\"ðŸ“Š Loaded prompts for {len(generated_prompts_for_classes)} classes\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"âŒ No generated prompts found. Will only run standard evaluation.\")\n",
        "        has_llm_prompts = False\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # Use context manager for proper model lifecycle management\n",
        "    with clip_model_context(\"ViT-B/16\") as (model, preprocess, device):\n",
        "        print(f\"ðŸ“± Using device: {device}\")\n",
        "        batch_sz = 128\n",
        "\n",
        "        # Load and prepare datasets\n",
        "        print(\"\\nðŸ“¥ Loading and preparing datasets...\")\n",
        "        train_set, val_set, test_set = get_data(transform=preprocess)\n",
        "        base_classes, novel_classes = base_novel_categories(train_set)\n",
        "\n",
        "        # Split datasets by base/novel classes\n",
        "        train_base, _ = split_data(train_set, base_classes)\n",
        "        val_base, _ = split_data(val_set, base_classes)\n",
        "        test_base, test_novel = split_data(test_set, base_classes)\n",
        "\n",
        "        print(f\"ðŸ“Š Dataset prepared:\")\n",
        "        print(f\"   Base classes: {len(base_classes)} Novel classes: {len(novel_classes)}\")\n",
        "        print(f\"   Test base samples: {len(test_base)} Test novel samples: {len(test_novel)}\")\n",
        "\n",
        "        # EVALUATION 1: Standard Base Classes\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"ðŸ”„ EVALUATION 1: Standard Prompts on Base Classes\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        base_text_features = get_text_features_standard(model, base_classes, device)\n",
        "        try:\n",
        "            results['standard_base'] = eval(\n",
        "                model=model,\n",
        "                dataset=test_base,\n",
        "                categories=base_classes,\n",
        "                batch_size=batch_sz,\n",
        "                device=device,\n",
        "                text_features=base_text_features,\n",
        "                label=\"ðŸ§  Zero-shot evaluation on Base Classes\"\n",
        "            )\n",
        "        finally:\n",
        "            del base_text_features\n",
        "            aggressive_cleanup()\n",
        "\n",
        "        # EVALUATION 2: Standard Novel Classes\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"ðŸ”„ EVALUATION 2: Standard Prompts on Novel Classes\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        novel_text_features = get_text_features_standard(model, novel_classes, device)\n",
        "        try:\n",
        "            results['standard_novel'] = eval(\n",
        "                model=model,\n",
        "                dataset=test_novel,\n",
        "                categories=novel_classes,\n",
        "                batch_size=batch_sz,\n",
        "                device=device,\n",
        "                text_features=novel_text_features,\n",
        "                label=\"ðŸ§  Zero-shot evaluation on Novel Classes\"\n",
        "            )\n",
        "        finally:\n",
        "            del novel_text_features\n",
        "            aggressive_cleanup()\n",
        "\n",
        "        # EVALUATIONS 3 & 4: LLM-Enhanced (if prompts available)\n",
        "        if has_llm_prompts:\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"ðŸ”„ EVALUATION 3: LLM-Enhanced Prompts on Base Classes\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "            base_llm_features = get_llm_text_features(\n",
        "                model, generated_prompts_for_classes, base_classes, CLASS_NAMES, device\n",
        "            )\n",
        "            try:\n",
        "                results['llm_base'] = eval(\n",
        "                    model=model,\n",
        "                    dataset=test_base,\n",
        "                    categories=base_classes,\n",
        "                    batch_size=batch_sz,\n",
        "                    device=device,\n",
        "                    text_features=base_llm_features,\n",
        "                    label=\"ðŸŒ¸ Zero-shot eval with LLM prompts on Base Classes\"\n",
        "                )\n",
        "            finally:\n",
        "                del base_llm_features\n",
        "                aggressive_cleanup()\n",
        "\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"ðŸ”„ EVALUATION 4: LLM-Enhanced Prompts on Novel Classes\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "            novel_llm_features = get_llm_text_features(\n",
        "                model, generated_prompts_for_classes, novel_classes, CLASS_NAMES, device\n",
        "            )\n",
        "            try:\n",
        "                results['llm_novel'] = eval(\n",
        "                    model=model,\n",
        "                    dataset=test_novel,\n",
        "                    categories=novel_classes,\n",
        "                    batch_size=batch_sz,\n",
        "                    device=device,\n",
        "                    text_features=novel_llm_features,\n",
        "                    label=\"ðŸŒ¸ Zero-shot eval with LLM prompts on Novel Classes\"\n",
        "                )\n",
        "            finally:\n",
        "                del novel_llm_features\n",
        "                aggressive_cleanup()\n",
        "\n",
        "    return results\n",
        "\n",
        "print(\"âœ… Main evaluation suite function defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "7cIZiEPU9wE4",
        "outputId": "7012a1f4-305d-44b4-f4cd-28909f41f31d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Main evaluation suite function defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Results\n",
        "def analyze_results(results):\n",
        "    \"\"\"\n",
        "    Analyze and display comprehensive results from all evaluations.\n",
        "\n",
        "    Calculates harmonic means between base and novel class performance,\n",
        "    which is a standard metric for few-shot learning evaluation.\n",
        "\n",
        "    Args:\n",
        "        results: Dictionary containing evaluation results\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ðŸ“Š COMPREHENSIVE RESULTS ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    def harmonic_mean(base_acc, novel_acc):\n",
        "        \"\"\"Calculate harmonic mean of two accuracies\"\"\"\n",
        "        if base_acc > 0 and novel_acc > 0:\n",
        "            return 2 / (1/base_acc + 1/novel_acc)\n",
        "        return 0\n",
        "\n",
        "    # Standard prompts analysis\n",
        "    if 'standard_base' in results and 'standard_novel' in results:\n",
        "        base_top1 = results['standard_base']['top1']\n",
        "        novel_top1 = results['standard_novel']['top1']\n",
        "        std_hm = harmonic_mean(base_top1, novel_top1)\n",
        "\n",
        "        print(\"ðŸ”¤ STANDARD PROMPTS RESULTS:\")\n",
        "        print(f\"   ðŸ“ˆ Harmonic Mean (Top-1): {std_hm*100:.2f}%\")\n",
        "        print(f\"   ðŸŽ¯ Base Classes Top-1:    {base_top1*100:.2f}%\")\n",
        "        print(f\"   ðŸ†• Novel Classes Top-1:   {novel_top1*100:.2f}%\")\n",
        "        print(f\"   ðŸ“Š Base Classes Top-5:    {results['standard_base']['top5']*100:.2f}%\")\n",
        "        print(f\"   ðŸ“Š Novel Classes Top-5:   {results['standard_novel']['top5']*100:.2f}%\")\n",
        "        print()\n",
        "\n",
        "    # LLM-enhanced prompts analysis\n",
        "    if 'llm_base' in results and 'llm_novel' in results:\n",
        "        base_top1_llm = results['llm_base']['top1']\n",
        "        novel_top1_llm = results['llm_novel']['top1']\n",
        "        llm_hm = harmonic_mean(base_top1_llm, novel_top1_llm)\n",
        "\n",
        "        print(\"ðŸ¤– LLM-ENHANCED PROMPTS RESULTS:\")\n",
        "        print(f\"   ðŸ“ˆ Harmonic Mean (Top-1): {llm_hm*100:.2f}%\")\n",
        "        print(f\"   ðŸŽ¯ Base Classes Top-1:    {base_top1_llm*100:.2f}%\")\n",
        "        print(f\"   ðŸ†• Novel Classes Top-1:   {novel_top1_llm*100:.2f}%\")\n",
        "        print(f\"   ðŸ“Š Base Classes Top-5:    {results['llm_base']['top5']*100:.2f}%\")\n",
        "        print(f\"   ðŸ“Š Novel Classes Top-5:   {results['llm_novel']['top5']*100:.2f}%\")\n",
        "        print()\n",
        "\n",
        "    # Improvement analysis\n",
        "    if all(key in results for key in ['standard_base', 'standard_novel', 'llm_base', 'llm_novel']):\n",
        "        base_improvement = (base_top1_llm - base_top1) * 100\n",
        "        novel_improvement = (novel_top1_llm - novel_top1) * 100\n",
        "        hm_improvement = (llm_hm - std_hm) * 100\n",
        "\n",
        "        print(\"ðŸ“ˆ IMPROVEMENT WITH LLM PROMPTS:\")\n",
        "        print(f\"   ðŸŽ¯ Base Classes:    {base_improvement:+.2f} percentage points\")\n",
        "        print(f\"   ðŸ†• Novel Classes:   {novel_improvement:+.2f} percentage points\")\n",
        "        print(f\"   ðŸ“ˆ Harmonic Mean:   {hm_improvement:+.2f} percentage points\")\n",
        "        print()\n",
        "\n",
        "    # Confidence gap analysis\n",
        "    print(\"ðŸ” CONFIDENCE GAP ANALYSIS:\")\n",
        "    for eval_name, eval_results in results.items():\n",
        "        eval_display = eval_name.replace('_', ' ').title()\n",
        "        print(f\"\\n   {eval_display}:\")\n",
        "        print(f\"     âœ… Top-1 Hit Gap:     {eval_results['avg_gap_top1_hit']:.2f}%\")\n",
        "        print(f\"     âŒ Top-5 Hit Gap:    {eval_results['avg_error_top5_hit']:.2f}%\")\n",
        "        print(f\"     âŒ Top-10 Hit Gap:   {eval_results['avg_error_top10_hit']:.2f}%\")\n",
        "        print(f\"     âŒ Top-10 Miss Gap:  {eval_results['avg_error_top10_miss']:.2f}%\")\n",
        "\n",
        "def save_results(results, filename=\"clip_evaluation_results.json\"):\n",
        "    \"\"\"Save results to JSON file for later analysis\"\"\"\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(results)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "aUau_-YT_XmU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zTnF4b47HMA",
        "outputId": "0d52bf5b-2350-48a4-ddc6-31c99ba73af3",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google GenAI SDK configured successfully!\n"
          ]
        }
      ],
      "source": [
        "#@title Gemini setup\n",
        "from google.colab import userdata\n",
        "\n",
        "# Configure the client\n",
        "GEMINI_API_KEY = \"AIzaSyB1eqziqPqvJwJKS9eSGlzgoMeZsFkhfIs\"\n",
        "client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# Define the grounding tool\n",
        "grounding_tool = types.Tool(\n",
        "    google_search=types.GoogleSearch()\n",
        ")\n",
        "\n",
        "# Configure generation settings for web search\n",
        "web_call_config = types.GenerateContentConfig(\n",
        "    tools=[grounding_tool]\n",
        ")\n",
        "\n",
        "# Define schema using Pydantic\n",
        "class Prompts(BaseModel):\n",
        "    d1: str\n",
        "    d2: str\n",
        "    d3: str\n",
        "    d4: str\n",
        "    d5: str\n",
        "    d6: str\n",
        "    d7: str\n",
        "\n",
        "class PromptDescriptions(BaseModel):\n",
        "    # This now expects a list of 'Prompts' objects\n",
        "    # And we enforce that this list must contain exactly the same number\n",
        "    # of elements as there are flower classes in the batch\n",
        "    descriptions: List[Prompts] = Field(\n",
        "        ..., # '...' indicates the field is required\n",
        "        min_length=1, # This will be dynamically set or handled in the loop\n",
        "        description=\"A list where each element is an object with 7 short descriptions for a specific category (d1-d10).\"\n",
        "    )\n",
        "\n",
        "# Configure generation settings for prompt generation\n",
        "prompt_gen_config = types.GenerateContentConfig(\n",
        "    temperature=0.0,\n",
        "    response_mime_type=\"application/json\",\n",
        "    response_schema=PromptDescriptions\n",
        ")\n",
        "\n",
        "def get_visual_features(class_name, dataset_name, generic_category)->str:\n",
        "  web_search_prompt = f\"\"\"What are the unique visual characteristics that distinguish an object of the class {class_name} within the {dataset_name} dataset?\n",
        "  If applicable, consider its features in relation to {generic_category} in general.\n",
        "  Please perform a web search to find reliable references to ensure the accuracy of the visual description.\n",
        "  Provide a detailed yet concise summary (bullet list style) (max 100 tokens) focusing exclusively on the visual features that are most helpful for differentiating this class from other classes within the dataset.\n",
        "  You should avoid writing information about the dataset\"\"\"\n",
        "\n",
        "  # Make the request\n",
        "  response = client.models.generate_content(\n",
        "      model=\"gemini-2.0-flash\",\n",
        "      contents=web_search_prompt,\n",
        "      config=web_call_config,\n",
        "  )\n",
        "\n",
        "  # Return the grounded response\n",
        "  return response.text\n",
        "\n",
        "print(\"Google GenAI SDK configured successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Feature Extraction and Saving (Resumable & Interactive)\n",
        "\n",
        "# --- Configuration for resuming ---\n",
        "output_filename = \"features.json\"\n",
        "starting_index = 0\n",
        "\n",
        "# --- Load existing features or create an empty list ---\n",
        "features = []\n",
        "if os.path.exists(output_filename):\n",
        "    try:\n",
        "        with open(output_filename, 'r') as f:\n",
        "            features = json.load(f)\n",
        "        print(f\"Loaded {len(features)} existing features from '{output_filename}'.\")\n",
        "        # Adjust starting_index if loaded features are more than starting_index\n",
        "        if starting_index < len(features):\n",
        "            print(f\"Adjusting starting_index to {len(features)} to append new entries.\")\n",
        "            starting_index = len(features)\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Warning: '{output_filename}' exists but is corrupted. Starting from scratch.\")\n",
        "        features = []\n",
        "else:\n",
        "    print(f\"'{output_filename}' not found. A new file will be created.\")\n",
        "\n",
        "# 1) features list and saving file are handled above.\n",
        "\n",
        "print(f\"Starting feature extraction from index {starting_index} for {len(CLASS_NAMES) - starting_index} remaining classes...\")\n",
        "\n",
        "last_successfully_saved_index = -1\n",
        "if features: # If features were loaded, the last index is length - 1\n",
        "    last_successfully_saved_index = len(features) - 1\n",
        "\n",
        "# Use slicing to iterate only over the remaining classes\n",
        "for i in tqdm(range(starting_index, len(CLASS_NAMES)), desc=\"Extracting features\"):\n",
        "    class_name = CLASS_NAMES[i]\n",
        "    print(f\"\\n--- Processing class {i+1}/{len(CLASS_NAMES)}: '{class_name}' (Index: {i}) ---\")\n",
        "\n",
        "    current_feature_description = None # To hold the result before user decision\n",
        "\n",
        "    try:\n",
        "        # Call the function to get visual features\n",
        "        current_feature_description = get_visual_features(class_name, dataset_name, generic_category)\n",
        "        print(f\"Description of {class_name}:\\n{current_feature_description}\")\n",
        "\n",
        "        user_input = input(\"Press C to save and continue, or A to abort: \").strip().upper()\n",
        "\n",
        "        if user_input != 'A':\n",
        "            # Ensure the features list has enough space up to the current index\n",
        "            # This handles cases where starting_index might have been manually set\n",
        "            while len(features) <= i:\n",
        "                features.append(None) # Pad with None if needed\n",
        "\n",
        "            features[i] = current_feature_description\n",
        "            print(f\"Description for '{class_name}' SAVED.\")\n",
        "\n",
        "            # Save the list into a features.json file immediately after saving a class\n",
        "            try:\n",
        "                with open(output_filename, 'w') as f:\n",
        "                    json.dump(features, f, indent=4)\n",
        "                print(f\"Features saved incrementally to '{output_filename}' (current count: {len(features)})\")\n",
        "                last_successfully_saved_index = i # Update last saved index\n",
        "            except Exception as e:\n",
        "                print(f\"CRITICAL ERROR: Could not save features to file after processing '{class_name}': {e}\")\n",
        "                print(\"Data might be lost if Colab session terminates. Please check file permissions or disk space.\")\n",
        "                # Even if saving failed, we continue unless 'A' was pressed, but warn the user.\n",
        "        else:\n",
        "            print(f\"Aborting execution. Description for '{class_name}' was NOT SAVED.\")\n",
        "            break # Exit the loop\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError processing class '{class_name}' at index {i}: {e}\")\n",
        "        print(\"Appending an error placeholder to maintain order if saving occurs. This entry will NOT be saved unless 'C' is pressed.\")\n",
        "        # If an error occurs, we still ask for user input to decide to save or abort.\n",
        "        # The user can decide to save the error placeholder or abort.\n",
        "        user_input_after_error = input(\"Error occurred. Press C to save an error placeholder and continue, or A to abort: \").strip().upper()\n",
        "\n",
        "        if user_input_after_error == 'C':\n",
        "            while len(features) <= i:\n",
        "                features.append(None) # Pad with None if needed\n",
        "            features[i] = f\"ERROR at index {i}: {e}\"\n",
        "            print(f\"Error placeholder for '{class_name}' SAVED.\")\n",
        "            try:\n",
        "                with open(output_filename, 'w') as f:\n",
        "                    json.dump(features, f, indent=4)\n",
        "                print(f\"Features saved incrementally to '{output_filename}' (current count: {len(features)})\")\n",
        "                last_successfully_saved_index = i\n",
        "            except Exception as e_save:\n",
        "                print(f\"CRITICAL ERROR: Could not save error placeholder to file after processing '{class_name}': {e_save}\")\n",
        "                print(\"Data might be lost if Colab session terminates. Please check file permissions or disk space.\")\n",
        "        elif user_input_after_error == 'A':\n",
        "            print(f\"Aborting execution due to error. Description for '{class_name}' was NOT SAVED.\")\n",
        "            break # Exit the loop\n",
        "        else:\n",
        "            print(f\"Invalid input after error ('{user_input_after_error}'). Skipping this class. Continuing to next.\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Feature Extraction Finished ---\")\n",
        "print(f\"Final count of features in list: {len(features)}\")\n",
        "if last_successfully_saved_index != -1:\n",
        "    print(f\"Last successfully saved class index: {last_successfully_saved_index} (Class: '{CLASS_NAMES[last_successfully_saved_index]}')\")\n",
        "else:\n",
        "    print(\"No classes were successfully saved during this run.\")"
      ],
      "metadata": {
        "id": "egWDTTzH-QkR",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "BqPWs3Wk8tM_",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "3a64edff042d43079400ef08f7b011e7",
            "79e150658347455e84f102da33346ebf",
            "b60b6fef65aa4d7d96a4bf758855c1e5",
            "66b33f908a0d4470b1685f7125920ff9",
            "2b514e17c68a47768526f3e3d84313a0",
            "a67327aa5bb0460eaef97704ba721511",
            "fe6b95b7519647938bdf29a488c06164",
            "5d3d0a843f7241baa85ec649d8ddf614",
            "5cb17b2aec0049bca31a5a038c828a37",
            "816f04149123462ea1bbcce9a99e422e",
            "ec64df42362b446d89b66242893166af"
          ]
        },
        "outputId": "04b22240-596d-4244-d6c6-5fb5bad36624",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Found features file\n",
            "ðŸ“Š Loaded features for 102 classes\n",
            "\n",
            "--- Generating the prompts for each class using LLM ---\n",
            "This might take a few minutes depending on the number of classes and API response times.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating prompts in batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a64edff042d43079400ef08f7b011e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LLM prompt generation complete.\n"
          ]
        }
      ],
      "source": [
        "# @title 3. LLM Prompt Generation (Batched Calls)\n",
        "\n",
        "generated_prompts_for_classes = {}  # {class_name: [list of prompts]}\n",
        "prompt_batch_size = 34\n",
        "# Try to load LLM-generated descriptions\n",
        "try:\n",
        "    with open(\"features.json\", \"r\") as f:\n",
        "        classes_features = json.load(f)\n",
        "    has_llm_descriptions = True\n",
        "    print(\"âœ… Found features file\")\n",
        "    print(f\"ðŸ“Š Loaded features for {len(classes_features)} classes\")\n",
        "except FileNotFoundError:\n",
        "    print(\"âŒ No features found. Will only run standard evaluation.\")\n",
        "    has_llm_descriptions = False\n",
        "\n",
        "print(\"\\n--- Generating the prompts for each class using LLM ---\")\n",
        "print(\"This might take a few minutes depending on the number of classes and API response times.\")\n",
        "\n",
        "for i in tqdm(range(0, len(CLASS_NAMES), prompt_batch_size), desc=\"Generating prompts in batches\"):\n",
        "    current_batch_classes = CLASS_NAMES[i : min(i + prompt_batch_size, len(CLASS_NAMES))]\n",
        "    current_batch_descriptions = classes_features[i : min(i + prompt_batch_size, len(classes_features))]\n",
        "\n",
        "    current_batch_for_llm = []\n",
        "    for class_name, description_string in zip(current_batch_classes, current_batch_descriptions):\n",
        "        current_batch_for_llm.append({\n",
        "            \"class_name\": class_name,\n",
        "            \"visual_features_description\": description_string.strip()\n",
        "        })\n",
        "    llm_input_json_string = json.dumps(current_batch_for_llm, indent=4)\n",
        "\n",
        "    # Dynamically build the prompt for the current batch\n",
        "    prompt_batch = f\"\"\"You are an expert in visual recognition and prompt engineering for Vision-Language Models (VLMs) like CLIP. Your task is to generate **7 diverse, concise, and highly discriminative text prompts** for each object class, specifically optimized for **zero-shot classification performance with CLIP**.\n",
        "\n",
        "You will be provided with a JSON list of object classes. For each object class in the list, you will receive:\n",
        "- `class_name`: The precise name of the object category.\n",
        "- `visual_features_description`: A detailed and reliable description of its key distinguishing visual characteristics. This description includes features that make the category unique. Rely more on this description than on your knowledge.\n",
        "\n",
        "**Your Goal:**\n",
        "For each `class_name` provided, generate exactly **5 distinct and effective text prompts**. These prompts should aim to maximize the accuracy of a CLIP model when classifying images of this particular class.\n",
        "\n",
        "**Guidelines for Prompt Construction:**\n",
        "1.  **Direct CLIP Alignment:** Focus exclusively on visual attributes that a VLM like CLIP can effectively recognize from an image. Avoid abstract concepts, misleading ategories names, or non-visual information.\n",
        "2.  **Leverage Visual Description:** Integrate key details from the `visual_features_description` into your prompts. This is crucial for distinguishing similar classes.\n",
        "3.  **Attribute Emphasis:** Clearly highlight unique visual traits such as color, shape, pattern, texture, size, or distinctive parts of the object.\n",
        "4.  **Contextualization & Image Type:** In addition to object-specific contexts, consider the dataset's characteristics. For the current dataset, which is '{dataset_name}', you should sometimes include terms describing the image style (sketch, drawing, professional photo, headshot, etc.) or broader environmental context relevant to the dataset (e.g. day/night, surroundings, distance, feeling).\n",
        "5.  **Conciseness & Token Limit:** Keep each prompt succinct, aiming for 20 tokens (10-12 words). Focus on high-signal visual words.\n",
        "6.  **Diversity for Ensembling:** Ensure the 5 prompts for a single class are not mere paraphrases. They should explore different facets of the class's visual identity, leading to diverse embeddings that enhance the power of prompt ensembling.\n",
        "\n",
        "**Input Classes for Prompt Generation:**\n",
        "```json\n",
        "{llm_input_json_string}\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "      response_llm = client.models.generate_content(\n",
        "          model=\"gemini-2.5-flash\",\n",
        "          contents=prompt_batch,\n",
        "          config=prompt_gen_config,\n",
        "      )\n",
        "\n",
        "      parsed_response = PromptDescriptions.model_validate_json(response_llm.text)\n",
        "\n",
        "      for j, prompt_obj in enumerate(parsed_response.descriptions):\n",
        "          category_name = current_batch_classes[j]\n",
        "          generated_prompts_for_classes[category_name] = [\n",
        "              prompt_obj.d1,\n",
        "              prompt_obj.d2,\n",
        "              prompt_obj.d3,\n",
        "              prompt_obj.d4,\n",
        "              prompt_obj.d5,\n",
        "              prompt_obj.d6,\n",
        "              prompt_obj.d7,\n",
        "          ]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError generating prompts for batch starting with '{current_batch_classes[0]}': {e}\")\n",
        "        print(f\"Raw response (if available): {response_llm.text if 'response_llm' in locals() else 'N/A'}\")\n",
        "\n",
        "print(\"\\nLLM prompt generation complete.\")\n",
        "\n",
        "with open(\"generated_prompts.json\", \"w\") as f:\n",
        "    json.dump(generated_prompts_for_classes, f, indent=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run Evaluation\n",
        "results = run_evaluation_suite()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "66758045094445f88b5434f0f0166f01",
            "d9a542fed83b4928bbd0a935af374ca7",
            "5951b8c3842e4bbfaec110e1aaade051",
            "675c67effebc42758ae4e080087c44f0",
            "b4c3ffa84c1e45458281bf8062880f2c",
            "f8fbebc94d634cf3b2d951a6512a18d9",
            "46137c37d25a4ada8560224134240a20",
            "9574dfbbaeca488b974f795d4215c151",
            "e237a75b2d16476aaf23fe8727db6c14",
            "453cd42488d044b18449ed7fcf66fa6c",
            "ca63fdd67f0440fdbb6f5a5ec1076b14",
            "cd1897325ea148caa92792672cf117cc",
            "ee79c4e2854d4deda04e73ecce666ea6",
            "cf6eda85925344c9bb48d03f2ba0b4b9",
            "00c50be62ceb492c8a840c0668fb59cd",
            "a3812d6158e44935b5046ec7f0157614",
            "7afb6b460c3a476cbb220d2b2af51c38",
            "bdc4d5740c9e435ebc1a4c16ab88fc0b",
            "771d966545594457a3f9495fa352fde6",
            "184fd733fc8e4525b171898ba18766f0",
            "a0871f4a61c844128a802fc54b9fbfe9",
            "9e2f752c05764eaa8b11785c0bc7e058",
            "7a95faa9d81a4e51a37ce8a20fce5500",
            "b0f6f4774c9e4be7bf0ae8492306e323",
            "d37172dd577f4482964257ce71123e58",
            "9b5f6cd76bca40c9b42adcc8d288cd4e",
            "fa0f027edfa1442e9eea552c64d9da49",
            "e218f8f1326b4f2dbb86dedfc093b5ad",
            "c953503912114653940d085444d6d3e9",
            "7c790da2baef40fd9ab928673800c6fc",
            "af12af8b58214ec88b145e631b8a0c25",
            "50c2095f21b84c718a1a26389feb5a5d",
            "0fa3962920964ad39273ae020cadcd4c",
            "882d371914144ac3bbd4affaa1fea3f3",
            "ab8626453ed047d5aa9dfecd1a1fbda6",
            "4125203699f44b609a6e19007c6ff419",
            "3187d750a08c40128e4c950ad7184f63",
            "30f33619ed644cc780bb545f17d94f3e",
            "fd01de21e35e455aaede9023766f32c1",
            "5f1ab39766aa4231baf08ecfea6a97ef",
            "0c1d3f14502049d1a7d3686b0f585fba",
            "98f18de0cb944634955dce2370315531",
            "60ff3a9fbeaa49ad8a929e0013d31f6a",
            "022a820b5a2d4d7f956ee21feb97d069"
          ]
        },
        "collapsed": true,
        "cellView": "form",
        "id": "imR1Bvc8GS1i",
        "outputId": "637b392f-fb02-4621-f868-1b00ed6c49d3"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Starting memory-optimized CLIP evaluation suite...\n",
            "âœ… Found generated prompts file\n",
            "ðŸ“Š Loaded prompts for 102 classes\n",
            "ðŸ¤– Loading CLIP model: ViT-B/16\n",
            "âœ… CLIP model loaded on cuda\n",
            "ðŸ“± Using device: cuda\n",
            "\n",
            "ðŸ“¥ Loading and preparing datasets...\n",
            "ðŸ“¥ Downloading and loading Flowers102 dataset...\n",
            "âœ… Dataset loaded - Train: 1020, Val: 1020, Test: 6149\n",
            "ðŸ“Š Class split - Base: 51, Novel: 51\n",
            "ðŸ“Š Data split - Base samples: 510, Novel samples: 510\n",
            "ðŸ“Š Data split - Base samples: 510, Novel samples: 510\n",
            "ðŸ“Š Data split - Base samples: 2473, Novel samples: 3676\n",
            "ðŸ“Š Dataset prepared:\n",
            "   Base classes: 51 Novel classes: 51\n",
            "   Test base samples: 2473 Test novel samples: 3676\n",
            "\n",
            "============================================================\n",
            "ðŸ”„ EVALUATION 1: Standard Prompts on Base Classes\n",
            "============================================================\n",
            "ðŸ“ Generated 51 standard prompts\n",
            "ðŸ“„ Example prompt: 'a photo of a pink primrose, a type of flower.'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ðŸ§  Zero-shot evaluation on Base Classes:   0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66758045094445f88b5434f0f0166f01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Total samples evaluated: 2473\n",
            "\n",
            "âœ… Top-1 Accuracy:      71.29%\n",
            "âœ… Top-5 Accuracy:      90.86%\n",
            "âœ… Top-10 Accuracy:     97.53%\n",
            "âœ… Avg. Conf. Gap (Top-1 hit):      3.27%\n",
            "âŒ Avg. Conf. Gap (Top-5 hit):     1.67%\n",
            "âŒ Avg. Conf. Gap (Top-10 hit):    3.86%\n",
            "âŒ Avg. Conf. Gap (Beyond top-10): 5.00%\n",
            "\n",
            "============================================================\n",
            "ðŸ”„ EVALUATION 2: Standard Prompts on Novel Classes\n",
            "============================================================\n",
            "ðŸ“ Generated 51 standard prompts\n",
            "ðŸ“„ Example prompt: 'a photo of a wild pansy, a type of flower.'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ðŸ§  Zero-shot evaluation on Novel Classes:   0%|          | 0/29 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd1897325ea148caa92792672cf117cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Total samples evaluated: 3676\n",
            "\n",
            "âœ… Top-1 Accuracy:      78.24%\n",
            "âœ… Top-5 Accuracy:      89.15%\n",
            "âœ… Top-10 Accuracy:     92.79%\n",
            "âœ… Avg. Conf. Gap (Top-1 hit):      3.69%\n",
            "âŒ Avg. Conf. Gap (Top-5 hit):     1.37%\n",
            "âŒ Avg. Conf. Gap (Top-10 hit):    3.45%\n",
            "âŒ Avg. Conf. Gap (Beyond top-10): 5.70%\n",
            "\n",
            "============================================================\n",
            "ðŸ”„ EVALUATION 3: LLM-Enhanced Prompts on Base Classes\n",
            "============================================================\n",
            "ðŸ¤– Processing LLM-generated prompts for 51 classes...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ðŸŒ¸ Zero-shot eval with LLM prompts on Base Classes:   0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a95faa9d81a4e51a37ce8a20fce5500"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Total samples evaluated: 2473\n",
            "\n",
            "âœ… Top-1 Accuracy:      77.07%\n",
            "âœ… Top-5 Accuracy:      94.86%\n",
            "âœ… Top-10 Accuracy:     98.79%\n",
            "âœ… Avg. Conf. Gap (Top-1 hit):      3.66%\n",
            "âŒ Avg. Conf. Gap (Top-5 hit):     1.97%\n",
            "âŒ Avg. Conf. Gap (Top-10 hit):    4.62%\n",
            "âŒ Avg. Conf. Gap (Beyond top-10): 6.12%\n",
            "\n",
            "============================================================\n",
            "ðŸ”„ EVALUATION 4: LLM-Enhanced Prompts on Novel Classes\n",
            "============================================================\n",
            "ðŸ¤– Processing LLM-generated prompts for 51 classes...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ðŸŒ¸ Zero-shot eval with LLM prompts on Novel Classes:   0%|          | 0/29 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "882d371914144ac3bbd4affaa1fea3f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Total samples evaluated: 3676\n",
            "\n",
            "âœ… Top-1 Accuracy:      78.40%\n",
            "âœ… Top-5 Accuracy:      91.57%\n",
            "âœ… Top-10 Accuracy:     93.12%\n",
            "âœ… Avg. Conf. Gap (Top-1 hit):      4.37%\n",
            "âŒ Avg. Conf. Gap (Top-5 hit):     1.49%\n",
            "âŒ Avg. Conf. Gap (Top-10 hit):    4.96%\n",
            "âŒ Avg. Conf. Gap (Beyond top-10): 9.95%\n",
            "ðŸ§¹ Cleaning up CLIP model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Show results\n",
        "analyze_results(results=results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "94W5dlyoGcc1",
        "outputId": "df0edc29-81d1-4921-efe7-fe532f0d75df"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ðŸ“Š COMPREHENSIVE RESULTS ANALYSIS\n",
            "============================================================\n",
            "ðŸ”¤ STANDARD PROMPTS RESULTS:\n",
            "   ðŸ“ˆ Harmonic Mean (Top-1): 74.60%\n",
            "   ðŸŽ¯ Base Classes Top-1:    71.29%\n",
            "   ðŸ†• Novel Classes Top-1:   78.24%\n",
            "   ðŸ“Š Base Classes Top-5:    90.86%\n",
            "   ðŸ“Š Novel Classes Top-5:   89.15%\n",
            "\n",
            "ðŸ¤– LLM-ENHANCED PROMPTS RESULTS:\n",
            "   ðŸ“ˆ Harmonic Mean (Top-1): 77.73%\n",
            "   ðŸŽ¯ Base Classes Top-1:    77.07%\n",
            "   ðŸ†• Novel Classes Top-1:   78.40%\n",
            "   ðŸ“Š Base Classes Top-5:    94.86%\n",
            "   ðŸ“Š Novel Classes Top-5:   91.57%\n",
            "\n",
            "ðŸ“ˆ IMPROVEMENT WITH LLM PROMPTS:\n",
            "   ðŸŽ¯ Base Classes:    +5.78 percentage points\n",
            "   ðŸ†• Novel Classes:   +0.16 percentage points\n",
            "   ðŸ“ˆ Harmonic Mean:   +3.13 percentage points\n",
            "\n",
            "ðŸ” CONFIDENCE GAP ANALYSIS:\n",
            "\n",
            "   Standard Base:\n",
            "     âœ… Top-1 Hit Gap:     3.27%\n",
            "     âŒ Top-5 Hit Gap:    1.67%\n",
            "     âŒ Top-10 Hit Gap:   3.86%\n",
            "     âŒ Top-10 Miss Gap:  5.00%\n",
            "\n",
            "   Standard Novel:\n",
            "     âœ… Top-1 Hit Gap:     3.69%\n",
            "     âŒ Top-5 Hit Gap:    1.37%\n",
            "     âŒ Top-10 Hit Gap:   3.45%\n",
            "     âŒ Top-10 Miss Gap:  5.70%\n",
            "\n",
            "   Llm Base:\n",
            "     âœ… Top-1 Hit Gap:     3.66%\n",
            "     âŒ Top-5 Hit Gap:    1.97%\n",
            "     âŒ Top-10 Hit Gap:   4.62%\n",
            "     âŒ Top-10 Miss Gap:  6.12%\n",
            "\n",
            "   Llm Novel:\n",
            "     âœ… Top-1 Hit Gap:     4.37%\n",
            "     âŒ Top-5 Hit Gap:    1.49%\n",
            "     âŒ Top-10 Hit Gap:   4.96%\n",
            "     âŒ Top-10 Miss Gap:  9.95%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3a64edff042d43079400ef08f7b011e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79e150658347455e84f102da33346ebf",
              "IPY_MODEL_b60b6fef65aa4d7d96a4bf758855c1e5",
              "IPY_MODEL_66b33f908a0d4470b1685f7125920ff9"
            ],
            "layout": "IPY_MODEL_2b514e17c68a47768526f3e3d84313a0"
          }
        },
        "79e150658347455e84f102da33346ebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a67327aa5bb0460eaef97704ba721511",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fe6b95b7519647938bdf29a488c06164",
            "value": "Generatingâ€‡promptsâ€‡inâ€‡batches:â€‡100%"
          }
        },
        "b60b6fef65aa4d7d96a4bf758855c1e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d3d0a843f7241baa85ec649d8ddf614",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5cb17b2aec0049bca31a5a038c828a37",
            "value": 3
          }
        },
        "66b33f908a0d4470b1685f7125920ff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_816f04149123462ea1bbcce9a99e422e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ec64df42362b446d89b66242893166af",
            "value": "â€‡3/3â€‡[02:44&lt;00:00,â€‡54.38s/it]"
          }
        },
        "2b514e17c68a47768526f3e3d84313a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a67327aa5bb0460eaef97704ba721511": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe6b95b7519647938bdf29a488c06164": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d3d0a843f7241baa85ec649d8ddf614": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cb17b2aec0049bca31a5a038c828a37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "816f04149123462ea1bbcce9a99e422e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec64df42362b446d89b66242893166af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66758045094445f88b5434f0f0166f01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9a542fed83b4928bbd0a935af374ca7",
              "IPY_MODEL_5951b8c3842e4bbfaec110e1aaade051",
              "IPY_MODEL_675c67effebc42758ae4e080087c44f0"
            ],
            "layout": "IPY_MODEL_b4c3ffa84c1e45458281bf8062880f2c"
          }
        },
        "d9a542fed83b4928bbd0a935af374ca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8fbebc94d634cf3b2d951a6512a18d9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_46137c37d25a4ada8560224134240a20",
            "value": "ðŸ§ â€‡Zero-shotâ€‡evaluationâ€‡onâ€‡Baseâ€‡Classes:â€‡100%"
          }
        },
        "5951b8c3842e4bbfaec110e1aaade051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9574dfbbaeca488b974f795d4215c151",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e237a75b2d16476aaf23fe8727db6c14",
            "value": 20
          }
        },
        "675c67effebc42758ae4e080087c44f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_453cd42488d044b18449ed7fcf66fa6c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ca63fdd67f0440fdbb6f5a5ec1076b14",
            "value": "â€‡20/20â€‡[00:28&lt;00:00,â€‡â€‡1.27s/it]"
          }
        },
        "b4c3ffa84c1e45458281bf8062880f2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8fbebc94d634cf3b2d951a6512a18d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46137c37d25a4ada8560224134240a20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9574dfbbaeca488b974f795d4215c151": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e237a75b2d16476aaf23fe8727db6c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "453cd42488d044b18449ed7fcf66fa6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca63fdd67f0440fdbb6f5a5ec1076b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd1897325ea148caa92792672cf117cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee79c4e2854d4deda04e73ecce666ea6",
              "IPY_MODEL_cf6eda85925344c9bb48d03f2ba0b4b9",
              "IPY_MODEL_00c50be62ceb492c8a840c0668fb59cd"
            ],
            "layout": "IPY_MODEL_a3812d6158e44935b5046ec7f0157614"
          }
        },
        "ee79c4e2854d4deda04e73ecce666ea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7afb6b460c3a476cbb220d2b2af51c38",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bdc4d5740c9e435ebc1a4c16ab88fc0b",
            "value": "ðŸ§ â€‡Zero-shotâ€‡evaluationâ€‡onâ€‡Novelâ€‡Classes:â€‡100%"
          }
        },
        "cf6eda85925344c9bb48d03f2ba0b4b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_771d966545594457a3f9495fa352fde6",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_184fd733fc8e4525b171898ba18766f0",
            "value": 29
          }
        },
        "00c50be62ceb492c8a840c0668fb59cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0871f4a61c844128a802fc54b9fbfe9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9e2f752c05764eaa8b11785c0bc7e058",
            "value": "â€‡29/29â€‡[00:39&lt;00:00,â€‡â€‡1.22s/it]"
          }
        },
        "a3812d6158e44935b5046ec7f0157614": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7afb6b460c3a476cbb220d2b2af51c38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdc4d5740c9e435ebc1a4c16ab88fc0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "771d966545594457a3f9495fa352fde6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "184fd733fc8e4525b171898ba18766f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0871f4a61c844128a802fc54b9fbfe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e2f752c05764eaa8b11785c0bc7e058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a95faa9d81a4e51a37ce8a20fce5500": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0f6f4774c9e4be7bf0ae8492306e323",
              "IPY_MODEL_d37172dd577f4482964257ce71123e58",
              "IPY_MODEL_9b5f6cd76bca40c9b42adcc8d288cd4e"
            ],
            "layout": "IPY_MODEL_fa0f027edfa1442e9eea552c64d9da49"
          }
        },
        "b0f6f4774c9e4be7bf0ae8492306e323": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e218f8f1326b4f2dbb86dedfc093b5ad",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c953503912114653940d085444d6d3e9",
            "value": "ðŸŒ¸â€‡Zero-shotâ€‡evalâ€‡withâ€‡LLMâ€‡promptsâ€‡onâ€‡Baseâ€‡Classes:â€‡100%"
          }
        },
        "d37172dd577f4482964257ce71123e58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c790da2baef40fd9ab928673800c6fc",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af12af8b58214ec88b145e631b8a0c25",
            "value": 20
          }
        },
        "9b5f6cd76bca40c9b42adcc8d288cd4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50c2095f21b84c718a1a26389feb5a5d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0fa3962920964ad39273ae020cadcd4c",
            "value": "â€‡20/20â€‡[00:26&lt;00:00,â€‡â€‡1.08s/it]"
          }
        },
        "fa0f027edfa1442e9eea552c64d9da49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e218f8f1326b4f2dbb86dedfc093b5ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c953503912114653940d085444d6d3e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c790da2baef40fd9ab928673800c6fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af12af8b58214ec88b145e631b8a0c25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50c2095f21b84c718a1a26389feb5a5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fa3962920964ad39273ae020cadcd4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "882d371914144ac3bbd4affaa1fea3f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab8626453ed047d5aa9dfecd1a1fbda6",
              "IPY_MODEL_4125203699f44b609a6e19007c6ff419",
              "IPY_MODEL_3187d750a08c40128e4c950ad7184f63"
            ],
            "layout": "IPY_MODEL_30f33619ed644cc780bb545f17d94f3e"
          }
        },
        "ab8626453ed047d5aa9dfecd1a1fbda6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd01de21e35e455aaede9023766f32c1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5f1ab39766aa4231baf08ecfea6a97ef",
            "value": "ðŸŒ¸â€‡Zero-shotâ€‡evalâ€‡withâ€‡LLMâ€‡promptsâ€‡onâ€‡Novelâ€‡Classes:â€‡100%"
          }
        },
        "4125203699f44b609a6e19007c6ff419": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c1d3f14502049d1a7d3686b0f585fba",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98f18de0cb944634955dce2370315531",
            "value": 29
          }
        },
        "3187d750a08c40128e4c950ad7184f63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60ff3a9fbeaa49ad8a929e0013d31f6a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_022a820b5a2d4d7f956ee21feb97d069",
            "value": "â€‡29/29â€‡[00:39&lt;00:00,â€‡â€‡1.17s/it]"
          }
        },
        "30f33619ed644cc780bb545f17d94f3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd01de21e35e455aaede9023766f32c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f1ab39766aa4231baf08ecfea6a97ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c1d3f14502049d1a7d3686b0f585fba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98f18de0cb944634955dce2370315531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60ff3a9fbeaa49ad8a929e0013d31f6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "022a820b5a2d4d7f956ee21feb97d069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}